{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "import json\n",
    "import yaml\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# hierarchical apply function on mixed dict/list struct\n",
    "def map_nested_struct_modify(ob, func):\n",
    "    if isinstance(ob,list):\n",
    "        for v in ob:\n",
    "            if isinstance(v,list) or isinstance(v,dict):\n",
    "                map_nested_struct_modify(v, func)\n",
    "            else:\n",
    "                v = func(v)    \n",
    "    elif isinstance(ob,dict):\n",
    "        for k, v in ob.items():\n",
    "            if isinstance(ob[k],list) or isinstance(ob[k],dict):\n",
    "                map_nested_struct_modify(v, func)\n",
    "            else:\n",
    "                ob[k] = func(v)\n",
    "    else:\n",
    "        ob = func(ob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if os.environ.get('JUPYTER_GATEWAY'):\n",
    "    path='/srv/notebooks'\n",
    "else:\n",
    "    path='.'\n",
    "    \n",
    "datapath = \"{}/datasets\".format(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "REQUEST = json.dumps({\n",
    "    'path' : {},\n",
    "    'args' : {}\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def response_dict(d, content_type='application/json'):\n",
    "    if content_type == 'application/json':\n",
    "        print(json.dumps(d))\n",
    "    elif content_type == 'application/xml' or content_type == 'text/xml':\n",
    "        print(yaml.dump(d))\n",
    "\n",
    "def response_meta(status=200, content_type='application/json'):\n",
    "    print(json.dumps({\n",
    "        \"headers\" : { \"Content-Type\" : content_type},\n",
    "        \"status\" : status\n",
    "    }))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def uniquify(seq): \n",
    "    checked = dict()\n",
    "    uniq = []\n",
    "    for e in seq:\n",
    "        if e not in checked.keys():\n",
    "            if e:\n",
    "                checked[e]=0\n",
    "                uniq.append(e)\n",
    "            else:\n",
    "                checked[e]=1\n",
    "                uniq.append('_1')\n",
    "        else:\n",
    "            checked[e] += 1\n",
    "            uniq.append('{}_{}'.format(e,checked[e]))\n",
    "    return uniq\n",
    "\n",
    "def to_alphanum(s):\n",
    "    return re.sub(r'[^0-9A-Za-z._]+', '', s).lower()\n",
    "\n",
    "def prep_names(seq):\n",
    "    names = [ to_alphanum(x)  for x in seq]\n",
    "    return uniquify(names)\n",
    "\n",
    "def dtype_to_string(x):\n",
    "    return {\n",
    "        'b': 'bool',\n",
    "        'i': 'long',\n",
    "        'u': 'long',\n",
    "        'f': 'double',\n",
    "        'c': 'complex',\n",
    "        'O': 'object',\n",
    "        'S': 'char',\n",
    "        'a': 'char',\n",
    "        'U': 'string',\n",
    "        'V': 'raw'\n",
    "    }.get(x[1], 'unknown')\n",
    "\n",
    "def is_number(s):\n",
    "    try:\n",
    "        complex(s) # for int, long, float and complex\n",
    "    except ValueError:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def is_float(s):\n",
    "    try:\n",
    "        float(s) # for int, long, float\n",
    "    except ValueError:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def is_int(s):\n",
    "    try:\n",
    "        return float(s).is_integer() # for int, long, float\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "def is_infinite(s):\n",
    "    try:\n",
    "        return np.isinf(float(s)) # for int, long, float\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "def is_zero(s):\n",
    "    return not s\n",
    "\n",
    "def vector_purity(x):\n",
    "    for i in list(range(len(x))):\n",
    "        # hard compressor\n",
    "        x[i] = max(0, min(1, x[i]))\n",
    "    return max(x)*(1 - (sum(x)-1)/(len(x)-1))\n",
    "\n",
    "def get_typestats(sr):\n",
    "    infinite= sum(sr.apply(is_infinite))\n",
    "    numeric = sum(sr.apply(is_number))\n",
    "    integer = sum(sr.apply(is_int))\n",
    "    nan     = sum(sr.isnull())\n",
    "    zero    = sum(sr.apply(is_zero))\n",
    "    unique  = len(sr.unique())\n",
    "    \n",
    "    count   = len(sr)\n",
    "    valid   = count-nan\n",
    "    quality = valid/count\n",
    "    \n",
    "    t = 'string' \n",
    "    if (integer/valid)>0.5 :\n",
    "        t = 'integer'\n",
    "    elif (numeric/valid)>0.5 :\n",
    "        t = 'numeric'\n",
    "    \n",
    "    # log vs linear?\n",
    "    cat = False\n",
    "    if (unique/valid)<0.1 :\n",
    "        cat = True\n",
    "    \n",
    "    numeric = numeric - integer - nan\n",
    "    string = count - numeric - integer\n",
    "    \n",
    "    d = { 'infinite': infinite,\n",
    "          'numeric' : numeric,\n",
    "          'integer' : integer,\n",
    "          'nan'     : nan,\n",
    "          'zero'    : zero,\n",
    "          'string'  : string,\n",
    "          'unique'  : unique,\n",
    "          'valid'   : valid,\n",
    "          'quality' : quality,\n",
    "          'descrete': cat,\n",
    "          'tcoerce' : t,\n",
    "          'tpurity' : vector_purity([integer/valid, numeric/valid, string/valid]),\n",
    "          'type'    : dtype_to_string(sr.dtype.str)\n",
    "    }\n",
    "    \n",
    "    return d\n",
    "\n",
    "def numpy2py(ob):\n",
    "    return np.asscalar(ob) if isinstance(ob, np.generic) else ob\n",
    "\n",
    "def format_float(ob):\n",
    "    return float(format(ob,'.2f')) if isinstance(ob, float) else ob\n",
    "\n",
    "def numpy_tojson(ob):\n",
    "    map_nested_struct_modify(ob, numpy2py)\n",
    "    map_nested_struct_modify(ob, format_float)\n",
    "    return ob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sr = pd.Series([1,0.0, '', '', np.inf, np.nan, 2.9, '0', '111', 'kkk'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'descrete': False,\n",
       " 'infinite': 1,\n",
       " 'integer': 4,\n",
       " 'nan': 1,\n",
       " 'numeric': 2,\n",
       " 'quality': 0.90000000000000002,\n",
       " 'string': 4,\n",
       " 'tcoerce': 'numeric',\n",
       " 'tpurity': 0.41975308641975306,\n",
       " 'type': 'object',\n",
       " 'unique': 9,\n",
       " 'valid': 9,\n",
       " 'zero': 3}"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_typestats(sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# help functions\n",
    "def rows_na_any(df):\n",
    "    na_df = pd.isnull(df)\n",
    "    d = na_df.apply(np.any, axis=0)\n",
    "    return len(d[d==True])\n",
    "\n",
    "def col_na_any(df):\n",
    "    na_df = pd.isnull(df)\n",
    "    d = na_df.apply(np.any, axis=1)\n",
    "    return len(d[d==True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df_meta = {\n",
    "    'id'   : '',\n",
    "    'name' : '',\n",
    "    'cols' : {}\n",
    "} \n",
    "\n",
    "def load_dataset(id):\n",
    "    global df, ds_meta\n",
    "    d = {\n",
    "        '0' : 'titanic.csv',\n",
    "        '1' : 'iris.csv',\n",
    "        '2' : 'pokemon.csv',\n",
    "        '3' : 'boston.csv'\n",
    "    }\n",
    "\n",
    "    filename = d.get(id, None)\n",
    "    \n",
    "    if filename==df_meta['name']:\n",
    "        return\n",
    "    \n",
    "    if filename:\n",
    "        df = pd.read_csv(\n",
    "            \"{}/{}\".format(datapath,filename), \n",
    "            sep=None, \n",
    "            engine='python', \n",
    "            true_values=['True', 'true'], \n",
    "            false_values=['False','false']\n",
    "        )\n",
    "\n",
    "        #dataset id\n",
    "        df_meta['id'] = id\n",
    "        df_meta['name'] = filename\n",
    "        df_meta['cols'] = dict(zip(prep_names(df.columns),df.columns))\n",
    "    \n",
    "        #rename df columns\n",
    "        df.columns = prep_names(df.columns)\n",
    "        \n",
    "        return True\n",
    "    else:\n",
    "        df = pd.DataFrame()\n",
    "        df_meta['id'] = id\n",
    "        df_meta['name'] = filename\n",
    "        df_meta['cols'] = {}\n",
    "        \n",
    "        return False\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\"name\": \"Species\", \"alias\": \"species\"}, {\"name\": \"Unnamed: 0\", \"alias\": \"unnamed0\"}, {\"name\": \"Petal.Length\", \"alias\": \"petal.length\"}, {\"name\": \"Petal.Width\", \"alias\": \"petal.width\"}, {\"name\": \"Sepal.Length\", \"alias\": \"sepal.length\"}, {\"name\": \"Sepal.Width\", \"alias\": \"sepal.width\"}]\n"
     ]
    }
   ],
   "source": [
    "# GET /datasets/:id\n",
    "\n",
    "if not os.environ.get('JUPYTER_GATEWAY'):\n",
    "    REQUEST = json.dumps({'path': {'id':'1'}})\n",
    "\n",
    "request = json.loads(REQUEST)\n",
    "dataset_id = request['path'].get('id')\n",
    "\n",
    "success = load_dataset(dataset_id)\n",
    "\n",
    "if not success:\n",
    "    response_dict('', 'application/json')\n",
    "else:\n",
    "    dv = []\n",
    "\n",
    "    #extract types\n",
    "    for alias,name in df_meta['cols'].items():\n",
    "        sr = df[alias]\n",
    "        dv.append(\n",
    "            {\n",
    "                'alias' : alias,\n",
    "                'name'  : name\n",
    "            }\n",
    "        )\n",
    "        \n",
    "    response_dict(dv, 'application/json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"status\": 200, \"headers\": {\"Content-Type\": \"application/json\"}}\n"
     ]
    }
   ],
   "source": [
    "# ResponseInfo GET /datasets/:id\n",
    "\n",
    "status = 404 if not df_meta['name'] else 200\n",
    "response_meta(status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cols': {'petal.length': 'Petal.Length',\n",
       "  'petal.width': 'Petal.Width',\n",
       "  'sepal.length': 'Sepal.Length',\n",
       "  'sepal.width': 'Sepal.Width',\n",
       "  'species': 'Species',\n",
       "  'unnamed0': 'Unnamed: 0'},\n",
       " 'id': '1',\n",
       " 'name': 'iris.csv'}"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"name\": \"titanic.csv\", \"cols\": 6, \"id\": \"0\", \"rows\": 32, \"na\": {\"cols\": 0, \"rows\": 0}, \"variables\": [{\"name\": \"Class\", \"type\": {\"zero\": 0, \"infinite\": 0, \"string\": 32, \"type\": \"object\", \"numeric\": 0, \"tcoerce\": \"string\", \"unique\": 4, \"valid\": 32, \"quality\": 1.0, \"descrete\": false, \"tpurity\": 1.0, \"nan\": 0, \"integer\": 0}, \"sample\": [\"2nd\", \"3rd\", \"3rd\", \"2nd\", \"Crew\", \"1st\", \"3rd\", \"2nd\", \"1st\", \"3rd\"], \"alias\": \"class\"}, {\"name\": \"Survived\", \"type\": {\"zero\": 0, \"infinite\": 0, \"string\": 32, \"type\": \"object\", \"numeric\": 0, \"tcoerce\": \"string\", \"unique\": 2, \"valid\": 32, \"quality\": 1.0, \"descrete\": true, \"tpurity\": 1.0, \"nan\": 0, \"integer\": 0}, \"sample\": [\"Yes\", \"No\", \"Yes\", \"Yes\", \"No\", \"Yes\", \"Yes\", \"No\", \"No\", \"No\"], \"alias\": \"survived\"}, {\"name\": \"Freq\", \"type\": {\"zero\": 8, \"infinite\": 0, \"string\": 0, \"type\": \"long\", \"numeric\": 0, \"tcoerce\": \"integer\", \"unique\": 22, \"valid\": 32, \"quality\": 1.0, \"descrete\": false, \"tpurity\": 1.0, \"nan\": 0, \"integer\": 32}, \"sample\": [\"14\", \"192\", \"0\", \"57\", \"3\", \"0\", \"4\", \"14\", \"140\", \"17\"], \"alias\": \"freq\"}, {\"name\": \"Unnamed: 0\", \"type\": {\"zero\": 0, \"infinite\": 0, \"string\": 0, \"type\": \"long\", \"numeric\": 0, \"tcoerce\": \"integer\", \"unique\": 32, \"valid\": 32, \"quality\": 1.0, \"descrete\": false, \"tpurity\": 1.0, \"nan\": 0, \"integer\": 32}, \"sample\": [\"5\", \"10\", \"16\", \"27\", \"28\", \"13\", \"8\", \"29\", \"21\", \"26\"], \"alias\": \"unnamed0\"}, {\"name\": \"Age\", \"type\": {\"zero\": 0, \"infinite\": 0, \"string\": 32, \"type\": \"object\", \"numeric\": 0, \"tcoerce\": \"string\", \"unique\": 2, \"valid\": 32, \"quality\": 1.0, \"descrete\": true, \"tpurity\": 1.0, \"nan\": 0, \"integer\": 0}, \"sample\": [\"Adult\", \"Adult\", \"Adult\", \"Adult\", \"Child\", \"Adult\", \"Adult\", \"Adult\", \"Adult\", \"Child\"], \"alias\": \"age\"}, {\"name\": \"Sex\", \"type\": {\"zero\": 0, \"infinite\": 0, \"string\": 32, \"type\": \"object\", \"numeric\": 0, \"tcoerce\": \"string\", \"unique\": 2, \"valid\": 32, \"quality\": 1.0, \"descrete\": true, \"tpurity\": 1.0, \"nan\": 0, \"integer\": 0}, \"sample\": [\"Male\", \"Female\", \"Female\", \"Female\", \"Female\", \"Male\", \"Female\", \"Male\", \"Female\", \"Female\"], \"alias\": \"sex\"}], \"dims\": 2}\n"
     ]
    }
   ],
   "source": [
    "# GET /datasets/:id/stats\n",
    "\n",
    "if not os.environ.get('JUPYTER_GATEWAY'):\n",
    "    REQUEST = json.dumps({'path': {'id':'0'}})\n",
    "\n",
    "request = json.loads(REQUEST)\n",
    "dataset_id = request['path'].get('id')\n",
    "\n",
    "success = load_dataset(dataset_id)\n",
    "\n",
    "if not success:\n",
    "    response_dict('', 'application/json')\n",
    "else:\n",
    "\n",
    "    #cell data\n",
    "    shape = df.shape\n",
    "\n",
    "    dv = []\n",
    "\n",
    "    #extract types\n",
    "    for alias,name in df_meta['cols'].items():\n",
    "        sr = df[alias]\n",
    "        dv.append(\n",
    "            {\n",
    "                'alias' : alias,\n",
    "                'name'  : name,\n",
    "                'type'  : get_typestats(sr),\n",
    "                'sample': [str(x) for x in sr.sample(n=10).tolist()]\n",
    "            }\n",
    "        )\n",
    "    \n",
    "    d = {\n",
    "        'name': df_meta['name'],\n",
    "        'id': df_meta['id'],\n",
    "        'dims': len(shape),\n",
    "        'rows': shape[0],\n",
    "        'cols': shape[1],\n",
    "        'na': {\n",
    "            'cols': rows_na_any(df),\n",
    "            'rows': col_na_any(df)\n",
    "        },\n",
    "        'variables': dv\n",
    "    }\n",
    "\n",
    "    #output\n",
    "    response_dict(numpy_tojson(d), 'application/json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"status\": 200, \"headers\": {\"Content-Type\": \"application/json\"}}\n"
     ]
    }
   ],
   "source": [
    "# ResponseInfo GET /datasets/:id/stats\n",
    "\n",
    "status = 404 if not df_meta['name'] else 200\n",
    "response_meta()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
